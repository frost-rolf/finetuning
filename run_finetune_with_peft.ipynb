{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["# Fine-Tune LLaMA 3.1-8B Instruct Model with PEFT (LoRA)\n"]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install torch transformers datasets accelerate peft"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
                "from peft import LoraConfig, get_peft_model, TaskType\n\n",
                "# Load the pre-trained model and tokenizer\n",
                "model_name = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                "model = AutoModelForCausalLM.from_pretrained(model_name)\n\n",
                "# Configure PEFT with LoRA\n",
                "peft_config = LoraConfig(\n",
                "    task_type=TaskType.CAUSAL_LM,    # Specify task type\n",
                "    r=8,                             # LoRA rank\n",
                "    lora_alpha=32,                   # LoRA scaling factor\n",
                "    lora_dropout=0.1,                # Dropout for LoRA layers\n",
                "    target_modules=[\"q_proj\", \"v_proj\"]  # Target attention layers\n",
                ")\n\n",
                "# Apply PEFT (LoRA)\n",
                "model = get_peft_model(model, peft_config)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import Trainer, TrainingArguments\n\n",
                "# Define training arguments\n",
                "training_args = TrainingArguments(\n",
                "    output_dir='./results',\n",
                "    evaluation_strategy='epoch',\n",
                "    per_device_train_batch_size=2,\n",
                "    per_device_eval_batch_size=2,\n",
                "    num_train_epochs=3,\n",
                "    logging_dir='./logs',\n",
                ")\n\n",
                "# Initialize the Trainer\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=train_dataset,\n",
                "    eval_dataset=eval_dataset,\n",
                ")\n\n",
                "# Start fine-tuning\n",
                "trainer.train()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}

